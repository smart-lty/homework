# 机器学习第二次作业

- 姓名：刘天宇
- 学号：2018312387
- 班级：计算机科学18

本次作业的任务是：

编程实现**线性判别分析**，并给出西瓜数据集3.0$\alpha$上的结果。

## 原理简介

`LDA`线性判别分析的目标是最大化“广义瑞利商”，即：
$$
J=\frac{w^TS_bw}{w^TS_ww}
$$
其中$S_w$为类内散度矩阵，$S_b$为类间散度矩阵。`LDA`想要找到合适的$w$来使$J$最大化。所以$w$的求法是：
$$
w = S^{-1}_w(\mu_0-\mu_1)
$$
具体求法见课本。

## 加载数据

```python
import numpy as np
import matplotlib.pyplot as plt

```

```python
def dataset():
    """
    create dataset manually.
    :return: X, Y
    """
    X = [[0.697, 0.460],
         [0.774, 0.376],
         [0.634, 0.264],
         [0.608, 0.318],
         [0.556, 0.215],
         [0.403, 0.237],
         [0.481, 0.149],
         [0.437, 0.211],
         [0.666, 0.091],
         [0.243, 0.267],
         [0.245, 0.057],
         [0.343, 0.099],
         [0.639, 0.161],
         [0.657, 0.198],
         [0.360, 0.370],
         [0.593, 0.042],
         [0.719, 0.103]]
    Y = [1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]
    return np.array(X), np.array(Y)
```

## 计算$w$

```python
def LDA():
    X, Y = dataset()
    pos = X[Y == 1]
    neg = X[Y == 0]

    # step 1: get the central vector of pos and neg
    pos_center = np.mean(pos, axis=0).reshape((-1, 1))
    neg_center = np.mean(neg, axis=0).reshape((-1, 1))

    # get covariance
    pos_cov = np.cov(pos, rowvar=False)
    neg_cov = np.cov(neg, rowvar=False)

    # get w
    S_w = np.mat(pos_cov + neg_cov)  # np.mat convert the array into matrix to compute inversed matrix
    w = S_w.I * (pos_center - neg_center)
    return pos, neg, w
```

## 结果可视化

```python
def plot_outcome():
    pos, neg, w = LDA()
    plt.style.use('ggplot')
    plt.scatter(pos[:, 0], pos[:, 1], c='#6495ED', label='pos')
    plt.scatter(neg[:, 0], neg[:, 1], c='#DC143C', label='neg')
    plt.plot([0, 1], [0, w[0] / w[1]], c='#FF7F50', label='LDA')
    plt.xlabel(r'Density')
    plt.ylabel(r'Sugar content')
    plt.title(r'Linear Discriminant Analysis', fontsize=15)

    plt.legend()
    plt.show()
```

最后，只需要运行`plot_outcome()`即可完成可视化！

